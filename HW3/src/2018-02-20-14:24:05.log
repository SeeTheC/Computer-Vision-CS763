2018-02-20-14:24:07 [DEBUG] Initializing Linear Layer
2018-02-20-14:24:28 [DEBUG] Initializing Criterion Layer
2018-02-20-14:24:28 [DEBUG] Beginning Gradient Descent
2018-02-20-14:24:31 [INFO ] Iteration: 1, Loss: 0.040495244095556
2018-02-20-14:24:34 [INFO ] Iteration: 2, Loss: 0.042469564132287
2018-02-20-14:24:38 [INFO ] Iteration: 3, Loss: 0.043403431159312
2018-02-20-14:24:41 [INFO ] Iteration: 4, Loss: 0.042527183244745
2018-02-20-14:24:44 [INFO ] Iteration: 5, Loss: 0.043479178970916
2018-02-20-14:24:48 [INFO ] Iteration: 6, Loss: 0.042163247170415
2018-02-20-14:24:51 [INFO ] Iteration: 7, Loss: 0.042260533710615
2018-02-20-14:24:54 [INFO ] Iteration: 8, Loss: 0.041808253747311
2018-02-20-14:24:57 [INFO ] Iteration: 9, Loss: 0.042643413564451
2018-02-20-14:25:00 [INFO ] Iteration: 10, Loss: 0.040934134962693
2018-02-20-14:25:03 [INFO ] Iteration: 11, Loss: 0.04158579400305
2018-02-20-14:25:07 [INFO ] Iteration: 12, Loss: 0.041656464578449
2018-02-20-14:25:09 [INFO ] Iteration: 13, Loss: 0.041548807818675
2018-02-20-14:25:13 [INFO ] Iteration: 14, Loss: 0.040616865042757
2018-02-20-14:25:16 [INFO ] Iteration: 15, Loss: 0.041699742941599
2018-02-20-14:25:19 [INFO ] Iteration: 16, Loss: 0.04060815852054
2018-02-20-14:25:22 [INFO ] Iteration: 17, Loss: 0.041344466669082
2018-02-20-14:25:26 [INFO ] Iteration: 18, Loss: 0.041641601888765
2018-02-20-14:25:29 [INFO ] Iteration: 19, Loss: 0.041920196931516
2018-02-20-14:25:32 [INFO ] Iteration: 20, Loss: 0.041659302224046
2018-02-20-14:25:34 [INFO ] Iteration: 21, Loss: 0.039701953632087
2018-02-20-14:25:37 [INFO ] Iteration: 22, Loss: 0.040741164039107
2018-02-20-14:25:40 [INFO ] Iteration: 23, Loss: 0.040598345600404
2018-02-20-14:25:43 [INFO ] Iteration: 24, Loss: 0.042329227601924
2018-02-20-14:25:47 [INFO ] Iteration: 25, Loss: 0.041363075297534
2018-02-20-14:25:49 [INFO ] Iteration: 26, Loss: 0.0405749925371
2018-02-20-14:25:52 [INFO ] Iteration: 27, Loss: 0.040870176954281
2018-02-20-14:25:55 [INFO ] Iteration: 28, Loss: 0.040433123594972
2018-02-20-14:25:59 [INFO ] Iteration: 29, Loss: 0.041452193365498
2018-02-20-14:26:01 [INFO ] Iteration: 30, Loss: 0.041479560069633
2018-02-20-14:26:04 [INFO ] Iteration: 31, Loss: 0.040186680235348
2018-02-20-14:26:07 [INFO ] Iteration: 32, Loss: 0.041478855284639
2018-02-20-14:26:11 [INFO ] Iteration: 33, Loss: 0.038993404939193
2018-02-20-14:26:13 [INFO ] Iteration: 34, Loss: 0.041263995272224
2018-02-20-14:26:16 [INFO ] Iteration: 35, Loss: 0.041359308385651
2018-02-20-14:26:19 [INFO ] Iteration: 36, Loss: 0.042216236528442
2018-02-20-14:26:22 [INFO ] Iteration: 37, Loss: 0.041246383346839
2018-02-20-14:26:24 [INFO ] Iteration: 38, Loss: 0.041853670687211
2018-02-20-14:26:28 [INFO ] Iteration: 39, Loss: 0.039933218639118
2018-02-20-14:26:31 [INFO ] Iteration: 40, Loss: 0.04265956446747
2018-02-20-14:26:34 [INFO ] Iteration: 41, Loss: 0.040786528533412
2018-02-20-14:26:36 [INFO ] Iteration: 42, Loss: 0.040521309682978
2018-02-20-14:26:39 [INFO ] Iteration: 43, Loss: 0.041208052542396
2018-02-20-14:26:42 [INFO ] Iteration: 44, Loss: 0.040389209574896
2018-02-20-14:26:45 [INFO ] Iteration: 45, Loss: 0.040835864877916
2018-02-20-14:26:48 [INFO ] Iteration: 46, Loss: 0.041498504305984
2018-02-20-14:26:51 [INFO ] Iteration: 47, Loss: 0.041661365427898
2018-02-20-14:26:54 [INFO ] Iteration: 48, Loss: 0.03987331751072
2018-02-20-14:26:57 [INFO ] Iteration: 49, Loss: 0.042978310973032
2018-02-20-14:27:00 [INFO ] Iteration: 50, Loss: 0.039087021420697
2018-02-20-14:27:03 [INFO ] Iteration: 51, Loss: 0.040526059293501
2018-02-20-14:27:06 [INFO ] Iteration: 52, Loss: 0.039376951998249
2018-02-20-14:27:09 [INFO ] Iteration: 53, Loss: 0.03915713966083
2018-02-20-14:27:12 [INFO ] Iteration: 54, Loss: 0.039961435709203
2018-02-20-14:27:15 [INFO ] Iteration: 55, Loss: 0.043506822164788
2018-02-20-14:27:18 [INFO ] Iteration: 56, Loss: 0.03903276613414
2018-02-20-14:27:21 [INFO ] Iteration: 57, Loss: 0.043281568833814
2018-02-20-14:27:24 [INFO ] Iteration: 58, Loss: 0.039829787618161
2018-02-20-14:27:27 [INFO ] Iteration: 59, Loss: 0.041918858645892
2018-02-20-14:27:30 [INFO ] Iteration: 60, Loss: 0.041160947887557
2018-02-20-14:27:32 [INFO ] Iteration: 61, Loss: 0.043234528193714
2018-02-20-14:27:36 [INFO ] Iteration: 62, Loss: 0.040069418703609
2018-02-20-14:27:39 [INFO ] Iteration: 63, Loss: 0.040508538282495
2018-02-20-14:27:42 [INFO ] Iteration: 64, Loss: 0.038686334013084
2018-02-20-14:27:45 [INFO ] Iteration: 65, Loss: 0.038580350899244
2018-02-20-14:27:47 [INFO ] Iteration: 66, Loss: 0.044791931380431
2018-02-20-14:27:51 [INFO ] Iteration: 67, Loss: 0.043273450720276
2018-02-20-14:27:54 [INFO ] Iteration: 68, Loss: 0.043458634292307
2018-02-20-14:27:57 [INFO ] Iteration: 69, Loss: 0.039636401140537
2018-02-20-14:27:59 [INFO ] Iteration: 70, Loss: 0.038487440478661
2018-02-20-14:28:03 [INFO ] Iteration: 71, Loss: 0.043141325786994
2018-02-20-14:28:05 [INFO ] Iteration: 72, Loss: 0.040461618474046
2018-02-20-14:28:08 [INFO ] Iteration: 73, Loss: 0.042153956058635
2018-02-20-14:28:11 [INFO ] Iteration: 74, Loss: 0.040968082948411
2018-02-20-14:28:15 [INFO ] Iteration: 75, Loss: 0.040683484333658
2018-02-20-14:28:18 [INFO ] Iteration: 76, Loss: 0.039475990598465
2018-02-20-14:28:21 [INFO ] Iteration: 77, Loss: 0.039929657721032
2018-02-20-14:28:23 [INFO ] Iteration: 78, Loss: 0.039816194548582
2018-02-20-14:28:27 [INFO ] Iteration: 79, Loss: 0.043266803796074
2018-02-20-14:28:29 [INFO ] Iteration: 80, Loss: 0.03908607933723
2018-02-20-14:28:32 [INFO ] Iteration: 81, Loss: 0.038508828700993
2018-02-20-14:28:35 [INFO ] Iteration: 82, Loss: 0.043452732170903
2018-02-20-14:28:39 [INFO ] Iteration: 83, Loss: 0.040898532515827
2018-02-20-14:28:41 [INFO ] Iteration: 84, Loss: 0.039964555045988
2018-02-20-14:28:44 [INFO ] Iteration: 85, Loss: 0.039618991285081
2018-02-20-14:28:47 [INFO ] Iteration: 86, Loss: 0.039751501715751
2018-02-20-14:28:50 [INFO ] Iteration: 87, Loss: 0.039410511644051
2018-02-20-14:28:53 [INFO ] Iteration: 88, Loss: 0.038853029055827
2018-02-20-14:28:56 [INFO ] Iteration: 89, Loss: 0.040035153668146
2018-02-20-14:28:59 [INFO ] Iteration: 90, Loss: 0.042750358634409
2018-02-20-14:29:02 [INFO ] Iteration: 91, Loss: 0.038356982228902
2018-02-20-14:29:05 [INFO ] Iteration: 92, Loss: 0.043715758583505
2018-02-20-14:29:08 [INFO ] Iteration: 93, Loss: 0.041064259427613
2018-02-20-14:29:11 [INFO ] Iteration: 94, Loss: 0.040941572047504
2018-02-20-14:29:14 [INFO ] Iteration: 95, Loss: 0.039119225680581
2018-02-20-14:29:18 [INFO ] Iteration: 96, Loss: 0.039124684068274
2018-02-20-14:29:21 [INFO ] Iteration: 97, Loss: 0.043813469767048
2018-02-20-14:29:23 [INFO ] Iteration: 98, Loss: 0.03885411517288
2018-02-20-14:29:27 [INFO ] Iteration: 99, Loss: 0.043422802293121
2018-02-20-14:29:29 [INFO ] Iteration: 100, Loss: 0.042205099256864
2018-02-20-14:29:32 [INFO ] Iteration: 101, Loss: 0.040052798255019
2018-02-20-14:29:36 [INFO ] Iteration: 102, Loss: 0.040046262833917
2018-02-20-14:29:39 [INFO ] Iteration: 103, Loss: 0.043425200046339
2018-02-20-14:29:42 [INFO ] Iteration: 104, Loss: 0.041889890746374
2018-02-20-14:29:44 [INFO ] Iteration: 105, Loss: 0.039696184999287
2018-02-20-14:29:47 [INFO ] Iteration: 106, Loss: 0.043632071577695
2018-02-20-14:29:50 [INFO ] Iteration: 107, Loss: 0.039953199649903
2018-02-20-14:29:54 [INFO ] Iteration: 108, Loss: 0.043155144001995
2018-02-20-14:29:56 [INFO ] Iteration: 109, Loss: 0.041908731989831
2018-02-20-14:29:59 [INFO ] Iteration: 110, Loss: 0.041986841694666
2018-02-20-14:30:02 [INFO ] Iteration: 111, Loss: 0.039916124607783
2018-02-20-14:30:05 [INFO ] Iteration: 112, Loss: 0.039678250406858
2018-02-20-14:30:08 [INFO ] Iteration: 113, Loss: 0.038995099388354
2018-02-20-14:30:10 [INFO ] Iteration: 114, Loss: 0.039805887717408
2018-02-20-14:30:14 [INFO ] Iteration: 115, Loss: 0.043054239484409
2018-02-20-14:30:17 [INFO ] Iteration: 116, Loss: 0.04236070199173
2018-02-20-14:30:19 [INFO ] Iteration: 117, Loss: 0.039608760507367
2018-02-20-14:30:22 [INFO ] Iteration: 118, Loss: 0.039106438788867
2018-02-20-14:30:25 [INFO ] Iteration: 119, Loss: 0.042644844481529
2018-02-20-14:30:29 [INFO ] Iteration: 120, Loss: 0.042479826761042
2018-02-20-14:30:31 [INFO ] Iteration: 121, Loss: 0.04063688055297
2018-02-20-14:30:34 [INFO ] Iteration: 122, Loss: 0.038944665853916
2018-02-20-14:30:37 [INFO ] Iteration: 123, Loss: 0.039749063174743
2018-02-20-14:30:40 [INFO ] Iteration: 124, Loss: 0.039370034477441
2018-02-20-14:30:43 [INFO ] Iteration: 125, Loss: 0.038569700770174
2018-02-20-14:30:45 [INFO ] Iteration: 126, Loss: 0.039380227147358
2018-02-20-14:30:48 [INFO ] Iteration: 127, Loss: 0.038351919855683
2018-02-20-14:30:51 [INFO ] Iteration: 128, Loss: 0.042837186446671
2018-02-20-14:30:54 [INFO ] Iteration: 129, Loss: 0.039901779084616
2018-02-20-14:30:56 [INFO ] Iteration: 130, Loss: 0.039417708099281
2018-02-20-14:31:00 [INFO ] Iteration: 131, Loss: 0.043547815112976
2018-02-20-14:31:03 [INFO ] Iteration: 132, Loss: 0.041713962394828
2018-02-20-14:31:06 [INFO ] Iteration: 133, Loss: 0.042058978297602
2018-02-20-14:31:08 [INFO ] Iteration: 134, Loss: 0.041469123508111
2018-02-20-14:31:11 [INFO ] Iteration: 135, Loss: 0.041447862650666
2018-02-20-14:31:15 [INFO ] Iteration: 136, Loss: 0.041578666783432
2018-02-20-14:31:17 [INFO ] Iteration: 137, Loss: 0.040359392983978
2018-02-20-14:31:20 [INFO ] Iteration: 138, Loss: 0.039404270658083
2018-02-20-14:31:23 [INFO ] Iteration: 139, Loss: 0.041649618900994
2018-02-20-14:31:26 [INFO ] Iteration: 140, Loss: 0.040512953607527
2018-02-20-14:31:29 [INFO ] Iteration: 141, Loss: 0.03973531676715
2018-02-20-14:31:31 [INFO ] Iteration: 142, Loss: 0.041302571724742
2018-02-20-14:31:35 [INFO ] Iteration: 143, Loss: 0.041329097070043
2018-02-20-14:31:37 [INFO ] Iteration: 144, Loss: 0.039189211125372
2018-02-20-14:31:40 [INFO ] Iteration: 145, Loss: 0.040126559035642
2018-02-20-14:31:43 [INFO ] Iteration: 146, Loss: 0.041134579623214
2018-02-20-14:31:46 [INFO ] Iteration: 147, Loss: 0.039663746682485
2018-02-20-14:31:50 [INFO ] Iteration: 148, Loss: 0.04141741900572
2018-02-20-14:31:52 [INFO ] Iteration: 149, Loss: 0.041228901227688
2018-02-20-14:31:55 [INFO ] Iteration: 150, Loss: 0.040226131448835
2018-02-20-14:31:58 [INFO ] Iteration: 151, Loss: 0.041777923160995
2018-02-20-14:32:01 [INFO ] Iteration: 152, Loss: 0.039654796113886
2018-02-20-14:32:04 [INFO ] Iteration: 153, Loss: 0.040857990599057
2018-02-20-14:32:07 [INFO ] Iteration: 154, Loss: 0.041676083634313
2018-02-20-14:32:10 [INFO ] Iteration: 155, Loss: 0.039681392648638
2018-02-20-14:32:13 [INFO ] Iteration: 156, Loss: 0.039392828793018
2018-02-20-14:32:16 [INFO ] Iteration: 157, Loss: 0.04002973712598
2018-02-20-14:32:18 [INFO ] Iteration: 158, Loss: 0.039167318654693
2018-02-20-14:32:22 [INFO ] Iteration: 159, Loss: 0.042313011669142
2018-02-20-14:32:25 [INFO ] Iteration: 160, Loss: 0.041955112697484
2018-02-20-14:32:28 [INFO ] Iteration: 161, Loss: 0.040791734332818
2018-02-20-14:32:30 [INFO ] Iteration: 162, Loss: 0.039872105013978
2018-02-20-14:32:34 [INFO ] Iteration: 163, Loss: 0.041705253676082
2018-02-20-14:32:37 [INFO ] Iteration: 164, Loss: 0.040892540263179
2018-02-20-14:32:40 [INFO ] Iteration: 165, Loss: 0.041101127483251
2018-02-20-14:32:42 [INFO ] Iteration: 166, Loss: 0.040503719656571
2018-02-20-14:32:46 [INFO ] Iteration: 167, Loss: 0.04067673562682
2018-02-20-14:32:49 [INFO ] Iteration: 168, Loss: 0.040998056763768
2018-02-20-14:32:51 [INFO ] Iteration: 169, Loss: 0.040495514335854
2018-02-20-14:32:54 [INFO ] Iteration: 170, Loss: 0.040022488120145
2018-02-20-14:32:57 [INFO ] Iteration: 171, Loss: 0.039296983547451
2018-02-20-14:32:59 [INFO ] Iteration: 172, Loss: 0.040984056882771
2018-02-20-14:33:02 [INFO ] Iteration: 173, Loss: 0.041997525085019
2018-02-20-14:33:04 [INFO ] Iteration: 174, Loss: 0.04066036186474
2018-02-20-14:33:07 [INFO ] Iteration: 175, Loss: 0.040079899446196
2018-02-20-14:33:09 [INFO ] Iteration: 176, Loss: 0.03962806195756
2018-02-20-14:33:12 [INFO ] Iteration: 177, Loss: 0.040666386100355
2018-02-20-14:33:15 [INFO ] Iteration: 178, Loss: 0.040926969882379
2018-02-20-14:33:17 [INFO ] Iteration: 179, Loss: 0.039413992874685
2018-02-20-14:33:20 [INFO ] Iteration: 180, Loss: 0.040958005590143
2018-02-20-14:33:22 [INFO ] Iteration: 181, Loss: 0.038956415884871
2018-02-20-14:33:25 [INFO ] Iteration: 182, Loss: 0.039173809684344
2018-02-20-14:33:28 [INFO ] Iteration: 183, Loss: 0.040298192914193
2018-02-20-14:33:30 [INFO ] Iteration: 184, Loss: 0.041384975505493
2018-02-20-14:33:33 [INFO ] Iteration: 185, Loss: 0.042041718888786
2018-02-20-14:33:35 [INFO ] Iteration: 186, Loss: 0.041703537054388
2018-02-20-14:33:38 [INFO ] Iteration: 187, Loss: 0.040472617719407
2018-02-20-14:33:40 [INFO ] Iteration: 188, Loss: 0.039293022334997
2018-02-20-14:33:43 [INFO ] Iteration: 189, Loss: 0.041469000837224
2018-02-20-14:33:46 [INFO ] Iteration: 190, Loss: 0.040688559981085
2018-02-20-14:33:48 [INFO ] Iteration: 191, Loss: 0.041529870819084
2018-02-20-14:33:51 [INFO ] Iteration: 192, Loss: 0.0415924969918
2018-02-20-14:33:53 [INFO ] Iteration: 193, Loss: 0.039923538415357
2018-02-20-14:33:56 [INFO ] Iteration: 194, Loss: 0.041209993484789
2018-02-20-14:33:59 [INFO ] Iteration: 195, Loss: 0.041165856130017
2018-02-20-14:34:01 [INFO ] Iteration: 196, Loss: 0.039973465780753
2018-02-20-14:34:04 [INFO ] Iteration: 197, Loss: 0.040103860495442
2018-02-20-14:34:07 [INFO ] Iteration: 198, Loss: 0.040419245791532
2018-02-20-14:34:09 [INFO ] Iteration: 199, Loss: 0.039987960389407
2018-02-20-14:34:12 [INFO ] Iteration: 200, Loss: 0.040623947539636
2018-02-20-14:34:15 [INFO ] Iteration: 201, Loss: 0.039471421576383
2018-02-20-14:34:17 [INFO ] Iteration: 202, Loss: 0.040337037995778
2018-02-20-14:34:20 [INFO ] Iteration: 203, Loss: 0.039838225711804
2018-02-20-14:34:22 [INFO ] Iteration: 204, Loss: 0.041218832803834
2018-02-20-14:34:25 [INFO ] Iteration: 205, Loss: 0.0395834011504
2018-02-20-14:34:28 [INFO ] Iteration: 206, Loss: 0.039947265880337
2018-02-20-14:34:30 [INFO ] Iteration: 207, Loss: 0.03996853676283
2018-02-20-14:34:33 [INFO ] Iteration: 208, Loss: 0.040458711386785
2018-02-20-14:34:36 [INFO ] Iteration: 209, Loss: 0.039991601012342
2018-02-20-14:34:38 [INFO ] Iteration: 210, Loss: 0.038987814221151
2018-02-20-14:34:41 [INFO ] Iteration: 211, Loss: 0.040311944999248
2018-02-20-14:34:44 [INFO ] Iteration: 212, Loss: 0.041558275842962
2018-02-20-14:34:46 [INFO ] Iteration: 213, Loss: 0.039486174472604
2018-02-20-14:34:49 [INFO ] Iteration: 214, Loss: 0.039730051010075
2018-02-20-14:34:51 [INFO ] Iteration: 215, Loss: 0.03982828205343
2018-02-20-14:34:54 [INFO ] Iteration: 216, Loss: 0.040953373364109
2018-02-20-14:34:56 [INFO ] Iteration: 217, Loss: 0.041267941045672
2018-02-20-14:34:59 [INFO ] Iteration: 218, Loss: 0.039685028731008
2018-02-20-14:35:02 [INFO ] Iteration: 219, Loss: 0.040834513711939
2018-02-20-14:35:04 [INFO ] Iteration: 220, Loss: 0.041409536951425
2018-02-20-14:35:07 [INFO ] Iteration: 221, Loss: 0.040201785778375
2018-02-20-14:35:09 [INFO ] Iteration: 222, Loss: 0.038990648071172
2018-02-20-14:35:12 [INFO ] Iteration: 223, Loss: 0.041532843750137
2018-02-20-14:35:15 [INFO ] Iteration: 224, Loss: 0.039424247557935
2018-02-20-14:35:17 [INFO ] Iteration: 225, Loss: 0.03983766947692
2018-02-20-14:35:20 [INFO ] Iteration: 226, Loss: 0.039167439128467
2018-02-20-14:35:22 [INFO ] Iteration: 227, Loss: 0.040665388059769
2018-02-20-14:35:25 [INFO ] Iteration: 228, Loss: 0.041076140692703
2018-02-20-14:35:27 [INFO ] Iteration: 229, Loss: 0.039873898492954
2018-02-20-14:35:30 [INFO ] Iteration: 230, Loss: 0.039969689497961
2018-02-20-14:35:33 [INFO ] Iteration: 231, Loss: 0.039738475498691
2018-02-20-14:35:35 [INFO ] Iteration: 232, Loss: 0.040417484042612
2018-02-20-14:35:38 [INFO ] Iteration: 233, Loss: 0.040594611267655
2018-02-20-14:35:40 [INFO ] Iteration: 234, Loss: 0.040188471128434
2018-02-20-14:35:43 [INFO ] Iteration: 235, Loss: 0.041482994064563
2018-02-20-14:35:46 [INFO ] Iteration: 236, Loss: 0.041611042545401
2018-02-20-14:35:48 [INFO ] Iteration: 237, Loss: 0.04126982997372
2018-02-20-14:35:51 [INFO ] Iteration: 238, Loss: 0.040645032076289
2018-02-20-14:35:53 [INFO ] Iteration: 239, Loss: 0.03986676930167
2018-02-20-14:35:56 [INFO ] Iteration: 240, Loss: 0.040012683478086
2018-02-20-14:35:58 [INFO ] Iteration: 241, Loss: 0.039718182467998
2018-02-20-14:36:01 [INFO ] Iteration: 242, Loss: 0.039821379138926
2018-02-20-14:36:04 [INFO ] Iteration: 243, Loss: 0.039619333944206
2018-02-20-14:36:06 [INFO ] Iteration: 244, Loss: 0.040798189845215
2018-02-20-14:36:09 [INFO ] Iteration: 245, Loss: 0.040671416685033
2018-02-20-14:36:11 [INFO ] Iteration: 246, Loss: 0.04069833475022
2018-02-20-14:36:14 [INFO ] Iteration: 247, Loss: 0.04039489312613
2018-02-20-14:36:17 [INFO ] Iteration: 248, Loss: 0.039124658714635
2018-02-20-14:36:19 [INFO ] Iteration: 249, Loss: 0.038910482156502
2018-02-20-14:36:22 [INFO ] Iteration: 250, Loss: 0.041118451671632
2018-02-20-14:36:24 [INFO ] Iteration: 251, Loss: 0.040003027000374
2018-02-20-14:36:27 [INFO ] Iteration: 252, Loss: 0.038885884245427
2018-02-20-14:36:29 [INFO ] Iteration: 253, Loss: 0.040980079443796
2018-02-20-14:36:32 [INFO ] Iteration: 254, Loss: 0.040260833998815
2018-02-20-14:36:35 [INFO ] Iteration: 255, Loss: 0.040067160455493
2018-02-20-14:36:37 [INFO ] Iteration: 256, Loss: 0.039376171350445
2018-02-20-14:36:40 [INFO ] Iteration: 257, Loss: 0.040086557228203
2018-02-20-14:36:42 [INFO ] Iteration: 258, Loss: 0.041892448437304
2018-02-20-14:36:45 [INFO ] Iteration: 259, Loss: 0.039633244981007
2018-02-20-14:36:48 [INFO ] Iteration: 260, Loss: 0.040136279554562
2018-02-20-14:36:50 [INFO ] Iteration: 261, Loss: 0.040169820931961
2018-02-20-14:36:53 [INFO ] Iteration: 262, Loss: 0.039508994386497
2018-02-20-14:36:55 [INFO ] Iteration: 263, Loss: 0.03890442099888
2018-02-20-14:36:58 [INFO ] Iteration: 264, Loss: 0.038518291423433
2018-02-20-14:37:01 [INFO ] Iteration: 265, Loss: 0.037744144740057
2018-02-20-14:37:03 [INFO ] Iteration: 266, Loss: 0.037971220928143
2018-02-20-14:37:06 [INFO ] Iteration: 267, Loss: 0.042666553732181
2018-02-20-14:37:08 [INFO ] Iteration: 268, Loss: 0.042394829429151
2018-02-20-14:37:11 [INFO ] Iteration: 269, Loss: 0.041934709363708
2018-02-20-14:37:14 [INFO ] Iteration: 270, Loss: 0.039534112002311
2018-02-20-14:37:16 [INFO ] Iteration: 271, Loss: 0.038745353204227
2018-02-20-14:37:19 [INFO ] Iteration: 272, Loss: 0.041972152165059
2018-02-20-14:37:21 [INFO ] Iteration: 273, Loss: 0.041918834766946
2018-02-20-14:37:24 [INFO ] Iteration: 274, Loss: 0.040719828765593
2018-02-20-14:37:26 [INFO ] Iteration: 275, Loss: 0.040456944569228
2018-02-20-14:37:29 [INFO ] Iteration: 276, Loss: 0.039471493947972
2018-02-20-14:37:32 [INFO ] Iteration: 277, Loss: 0.03869301733927
2018-02-20-14:37:34 [INFO ] Iteration: 278, Loss: 0.040613537381487
2018-02-20-14:37:37 [INFO ] Iteration: 279, Loss: 0.040716113033349
2018-02-20-14:37:39 [INFO ] Iteration: 280, Loss: 0.039702702444033
2018-02-20-14:37:42 [INFO ] Iteration: 281, Loss: 0.039211911688662
2018-02-20-14:37:45 [INFO ] Iteration: 282, Loss: 0.040549767032568
2018-02-20-14:37:47 [INFO ] Iteration: 283, Loss: 0.039932008232649
2018-02-20-14:37:50 [INFO ] Iteration: 284, Loss: 0.040490338075175
2018-02-20-14:37:52 [INFO ] Iteration: 285, Loss: 0.038905922092311
2018-02-20-14:37:55 [INFO ] Iteration: 286, Loss: 0.040785283732878
2018-02-20-14:37:57 [INFO ] Iteration: 287, Loss: 0.038780079764162
2018-02-20-14:38:00 [INFO ] Iteration: 288, Loss: 0.038966451379601
2018-02-20-14:38:03 [INFO ] Iteration: 289, Loss: 0.038402902982509
2018-02-20-14:38:05 [INFO ] Iteration: 290, Loss: 0.038603047521465
2018-02-20-14:38:08 [INFO ] Iteration: 291, Loss: 0.041338148145644
2018-02-20-14:38:10 [INFO ] Iteration: 292, Loss: 0.039409806358729
2018-02-20-14:38:13 [INFO ] Iteration: 293, Loss: 0.038796046915232
2018-02-20-14:38:16 [INFO ] Iteration: 294, Loss: 0.040065934435171
2018-02-20-14:38:18 [INFO ] Iteration: 295, Loss: 0.041377113533032
2018-02-20-14:38:21 [INFO ] Iteration: 296, Loss: 0.040370578447697
2018-02-20-14:38:24 [INFO ] Iteration: 297, Loss: 0.04045075809735
2018-02-20-14:38:26 [INFO ] Iteration: 298, Loss: 0.039764990865583
2018-02-20-14:38:29 [INFO ] Iteration: 299, Loss: 0.039755025784419
2018-02-20-14:38:31 [INFO ] Iteration: 300, Loss: 0.041235138382458
2018-02-20-14:38:34 [INFO ] Iteration: 301, Loss: 0.040199555285207
2018-02-20-14:38:37 [INFO ] Iteration: 302, Loss: 0.039748289375566
2018-02-20-14:38:39 [INFO ] Iteration: 303, Loss: 0.03977374162433
2018-02-20-14:38:42 [INFO ] Iteration: 304, Loss: 0.039424522269469
2018-02-20-14:38:45 [INFO ] Iteration: 305, Loss: 0.040708756743021
2018-02-20-14:38:47 [INFO ] Iteration: 306, Loss: 0.03872464611534
2018-02-20-14:38:50 [INFO ] Iteration: 307, Loss: 0.040350933195181
2018-02-20-14:38:53 [INFO ] Iteration: 308, Loss: 0.038314234118424
2018-02-20-14:38:55 [INFO ] Iteration: 309, Loss: 0.040574560935562
2018-02-20-14:38:58 [INFO ] Iteration: 310, Loss: 0.040298251707707
2018-02-20-14:39:01 [INFO ] Iteration: 311, Loss: 0.039313943345835
2018-02-20-14:39:03 [INFO ] Iteration: 312, Loss: 0.038363495842736
2018-02-20-14:39:06 [INFO ] Iteration: 313, Loss: 0.039097562818268
2018-02-20-14:39:08 [INFO ] Iteration: 314, Loss: 0.039800235542682
2018-02-20-14:39:11 [INFO ] Iteration: 315, Loss: 0.041007046762718
2018-02-20-14:39:14 [INFO ] Iteration: 316, Loss: 0.038147461904995
2018-02-20-14:39:16 [INFO ] Iteration: 317, Loss: 0.041217505984243
2018-02-20-14:39:19 [INFO ] Iteration: 318, Loss: 0.041069379121997
2018-02-20-14:39:22 [INFO ] Iteration: 319, Loss: 0.039191990152148
2018-02-20-14:39:24 [INFO ] Iteration: 320, Loss: 0.040681457337791
2018-02-20-14:39:27 [INFO ] Iteration: 321, Loss: 0.038931495251908
2018-02-20-14:39:30 [INFO ] Iteration: 322, Loss: 0.040038811441853
2018-02-20-14:39:32 [INFO ] Iteration: 323, Loss: 0.040096218496731
2018-02-20-14:39:35 [INFO ] Iteration: 324, Loss: 0.040985041143399
2018-02-20-14:39:38 [INFO ] Iteration: 325, Loss: 0.039670683302747
2018-02-20-14:39:40 [INFO ] Iteration: 326, Loss: 0.040543204651906
2018-02-20-14:39:43 [INFO ] Iteration: 327, Loss: 0.039884597098359
2018-02-20-14:39:45 [INFO ] Iteration: 328, Loss: 0.039927933501128
2018-02-20-14:39:48 [INFO ] Iteration: 329, Loss: 0.03919062157407
2018-02-20-14:39:51 [INFO ] Iteration: 330, Loss: 0.039784831224587
2018-02-20-14:39:53 [INFO ] Iteration: 331, Loss: 0.04000978576573
2018-02-20-14:39:56 [INFO ] Iteration: 332, Loss: 0.038949022717782
2018-02-20-14:39:59 [INFO ] Iteration: 333, Loss: 0.038778152793621
2018-02-20-14:40:01 [INFO ] Iteration: 334, Loss: 0.039622622712337
2018-02-20-14:40:04 [INFO ] Iteration: 335, Loss: 0.038855738921263
2018-02-20-14:40:07 [INFO ] Iteration: 336, Loss: 0.039373582482361
2018-02-20-14:40:09 [INFO ] Iteration: 337, Loss: 0.037621566067561
2018-02-20-14:40:12 [INFO ] Iteration: 338, Loss: 0.037177080509418
2018-02-20-14:40:15 [INFO ] Iteration: 339, Loss: 0.040367129135867
2018-02-20-14:40:17 [INFO ] Iteration: 340, Loss: 0.039606983935505
2018-02-20-14:40:20 [INFO ] Iteration: 341, Loss: 0.039907432571272
2018-02-20-14:40:22 [INFO ] Iteration: 342, Loss: 0.040833471321691
2018-02-20-14:40:25 [INFO ] Iteration: 343, Loss: 0.038501318650978
2018-02-20-14:40:28 [INFO ] Iteration: 344, Loss: 0.041837797788479
2018-02-20-14:40:30 [INFO ] Iteration: 345, Loss: 0.039184589586681
2018-02-20-14:40:33 [INFO ] Iteration: 346, Loss: 0.040277637916322
2018-02-20-14:40:36 [INFO ] Iteration: 347, Loss: 0.039559697223477
2018-02-20-14:40:38 [INFO ] Iteration: 348, Loss: 0.038804974775902
2018-02-20-14:40:41 [INFO ] Iteration: 349, Loss: 0.040781531322135
2018-02-20-14:40:44 [INFO ] Iteration: 350, Loss: 0.041286433209816
2018-02-20-14:40:46 [INFO ] Iteration: 351, Loss: 0.03846646561875
2018-02-20-14:40:49 [INFO ] Iteration: 352, Loss: 0.041422524614449
2018-02-20-14:40:52 [INFO ] Iteration: 353, Loss: 0.040618823916
2018-02-20-14:40:54 [INFO ] Iteration: 354, Loss: 0.039818487402513
2018-02-20-14:40:57 [INFO ] Iteration: 355, Loss: 0.039583735120266
2018-02-20-14:40:59 [INFO ] Iteration: 356, Loss: 0.039427243767979
2018-02-20-14:41:02 [INFO ] Iteration: 357, Loss: 0.038932549133991
2018-02-20-14:41:05 [INFO ] Iteration: 358, Loss: 0.040480769456288
2018-02-20-14:41:07 [INFO ] Iteration: 359, Loss: 0.038746030861662
2018-02-20-14:41:10 [INFO ] Iteration: 360, Loss: 0.041040161350254
2018-02-20-14:41:13 [INFO ] Iteration: 361, Loss: 0.039983932771626
2018-02-20-14:41:15 [INFO ] Iteration: 362, Loss: 0.038429108913975
2018-02-20-14:41:18 [INFO ] Iteration: 363, Loss: 0.040382201425531
2018-02-20-14:41:21 [INFO ] Iteration: 364, Loss: 0.040411676868872
2018-02-20-14:41:23 [INFO ] Iteration: 365, Loss: 0.039705767305816
2018-02-20-14:41:26 [INFO ] Iteration: 366, Loss: 0.039856827036994
2018-02-20-14:41:28 [INFO ] Iteration: 367, Loss: 0.039865377239764
2018-02-20-14:41:31 [INFO ] Iteration: 368, Loss: 0.03903404417896
2018-02-20-14:41:34 [INFO ] Iteration: 369, Loss: 0.038161304874316
2018-02-20-14:41:36 [INFO ] Iteration: 370, Loss: 0.03893941685734
2018-02-20-14:41:39 [INFO ] Iteration: 371, Loss: 0.040019001567102
2018-02-20-14:41:42 [INFO ] Iteration: 372, Loss: 0.040613349362951
2018-02-20-14:41:44 [INFO ] Iteration: 373, Loss: 0.039479355976251
2018-02-20-14:41:47 [INFO ] Iteration: 374, Loss: 0.038912234155119
2018-02-20-14:41:50 [INFO ] Iteration: 375, Loss: 0.040369675561666
2018-02-20-14:41:52 [INFO ] Iteration: 376, Loss: 0.041942138981408
2018-02-20-14:41:55 [INFO ] Iteration: 377, Loss: 0.04108637863296
2018-02-20-14:41:58 [INFO ] Iteration: 378, Loss: 0.039668658276508
2018-02-20-14:42:00 [INFO ] Iteration: 379, Loss: 0.039375491111721
2018-02-20-14:42:03 [INFO ] Iteration: 380, Loss: 0.039517928735717
2018-02-20-14:42:05 [INFO ] Iteration: 381, Loss: 0.038438751112038
2018-02-20-14:42:08 [INFO ] Iteration: 382, Loss: 0.04171253671864
2018-02-20-14:42:11 [INFO ] Iteration: 383, Loss: 0.040643909381115
2018-02-20-14:42:13 [INFO ] Iteration: 384, Loss: 0.039111464204348
2018-02-20-14:42:16 [INFO ] Iteration: 385, Loss: 0.040155429939542
2018-02-20-14:42:19 [INFO ] Iteration: 386, Loss: 0.041119544016671
2018-02-20-14:42:21 [INFO ] Iteration: 387, Loss: 0.039436286898011
2018-02-20-14:42:24 [INFO ] Iteration: 388, Loss: 0.039261490738582
2018-02-20-14:42:27 [INFO ] Iteration: 389, Loss: 0.038998647119122
2018-02-20-14:42:29 [INFO ] Iteration: 390, Loss: 0.041158538885508
2018-02-20-14:42:32 [INFO ] Iteration: 391, Loss: 0.037828601018955
2018-02-20-14:42:35 [INFO ] Iteration: 392, Loss: 0.038685878802974
2018-02-20-14:42:37 [INFO ] Iteration: 393, Loss: 0.040998593074965
2018-02-20-14:42:40 [INFO ] Iteration: 394, Loss: 0.037702475533867
2018-02-20-14:42:42 [INFO ] Iteration: 395, Loss: 0.040316980228179
2018-02-20-14:42:45 [INFO ] Iteration: 396, Loss: 0.040322914694477
2018-02-20-14:42:48 [INFO ] Iteration: 397, Loss: 0.038313226045095
2018-02-20-14:42:50 [INFO ] Iteration: 398, Loss: 0.040184832638962
2018-02-20-14:42:53 [INFO ] Iteration: 399, Loss: 0.040456979737832
2018-02-20-14:42:56 [INFO ] Iteration: 400, Loss: 0.039188708686785
2018-02-20-14:42:58 [INFO ] Iteration: 401, Loss: 0.040066998713223
2018-02-20-14:43:01 [INFO ] Iteration: 402, Loss: 0.039225547182209
2018-02-20-14:43:04 [INFO ] Iteration: 403, Loss: 0.040247988651991
2018-02-20-14:43:06 [INFO ] Iteration: 404, Loss: 0.040394762887789
2018-02-20-14:43:09 [INFO ] Iteration: 405, Loss: 0.039834537410973
2018-02-20-14:43:12 [INFO ] Iteration: 406, Loss: 0.03992982621843
2018-02-20-14:43:14 [INFO ] Iteration: 407, Loss: 0.0393715322604
2018-02-20-14:43:17 [INFO ] Iteration: 408, Loss: 0.038704932621454
2018-02-20-14:43:19 [INFO ] Iteration: 409, Loss: 0.037695091323035
2018-02-20-14:43:22 [INFO ] Iteration: 410, Loss: 0.037245864531003
2018-02-20-14:43:25 [INFO ] Iteration: 411, Loss: 0.04028109872624
2018-02-20-14:43:27 [INFO ] Iteration: 412, Loss: 0.039503908875343
2018-02-20-14:43:30 [INFO ] Iteration: 413, Loss: 0.038450807555826
2018-02-20-14:43:33 [INFO ] Iteration: 414, Loss: 0.041162091678868
2018-02-20-14:43:35 [INFO ] Iteration: 415, Loss: 0.039391529156095
2018-02-20-14:43:38 [INFO ] Iteration: 416, Loss: 0.039535721750727
2018-02-20-14:43:41 [INFO ] Iteration: 417, Loss: 0.039986544063064
2018-02-20-14:43:43 [INFO ] Iteration: 418, Loss: 0.039320474140892
2018-02-20-14:43:46 [INFO ] Iteration: 419, Loss: 0.040152567996276
2018-02-20-14:43:48 [INFO ] Iteration: 420, Loss: 0.039407128280726
2018-02-20-14:43:51 [INFO ] Iteration: 421, Loss: 0.039265964145766
2018-02-20-14:43:54 [INFO ] Iteration: 422, Loss: 0.038293908708942
2018-02-20-14:43:56 [INFO ] Iteration: 423, Loss: 0.039494085424401
2018-02-20-14:43:59 [INFO ] Iteration: 424, Loss: 0.039749145542452
2018-02-20-14:44:02 [INFO ] Iteration: 425, Loss: 0.040244277709022
2018-02-20-14:44:04 [INFO ] Iteration: 426, Loss: 0.038567221915821
2018-02-20-14:44:07 [INFO ] Iteration: 427, Loss: 0.039750541792475
2018-02-20-14:44:10 [INFO ] Iteration: 428, Loss: 0.038707986552787
2018-02-20-14:44:12 [INFO ] Iteration: 429, Loss: 0.038856769065996
2018-02-20-14:44:15 [INFO ] Iteration: 430, Loss: 0.040072061646596
2018-02-20-14:44:18 [INFO ] Iteration: 431, Loss: 0.039337323833831
2018-02-20-14:44:20 [INFO ] Iteration: 432, Loss: 0.039288497946574
2018-02-20-14:44:23 [INFO ] Iteration: 433, Loss: 0.038662139031068
2018-02-20-14:44:25 [INFO ] Iteration: 434, Loss: 0.039237756700441
2018-02-20-14:44:28 [INFO ] Iteration: 435, Loss: 0.038453703845486
2018-02-20-14:44:31 [INFO ] Iteration: 436, Loss: 0.039682930367868
2018-02-20-14:44:33 [INFO ] Iteration: 437, Loss: 0.038804334944786
2018-02-20-14:44:36 [INFO ] Iteration: 438, Loss: 0.040300507045194
2018-02-20-14:44:39 [INFO ] Iteration: 439, Loss: 0.039558947885035
2018-02-20-14:44:41 [INFO ] Iteration: 440, Loss: 0.039364182392249
2018-02-20-14:44:44 [INFO ] Iteration: 441, Loss: 0.03874404957543
2018-02-20-14:44:47 [INFO ] Iteration: 442, Loss: 0.039500025490901
2018-02-20-14:44:49 [INFO ] Iteration: 443, Loss: 0.038910647076373
2018-02-20-14:44:52 [INFO ] Iteration: 444, Loss: 0.039822121403484
2018-02-20-14:44:55 [INFO ] Iteration: 445, Loss: 0.03877888620868
2018-02-20-14:44:57 [INFO ] Iteration: 446, Loss: 0.038461133424602
2018-02-20-14:45:00 [INFO ] Iteration: 447, Loss: 0.038877447243655
2018-02-20-14:45:02 [INFO ] Iteration: 448, Loss: 0.038351878520904
2018-02-20-14:45:05 [INFO ] Iteration: 449, Loss: 0.038977964407611
2018-02-20-14:45:08 [INFO ] Iteration: 450, Loss: 0.039847783433808
2018-02-20-14:45:10 [INFO ] Iteration: 451, Loss: 0.039515887459133
2018-02-20-14:45:13 [INFO ] Iteration: 452, Loss: 0.040359634568863
2018-02-20-14:45:16 [INFO ] Iteration: 453, Loss: 0.039288410601541
2018-02-20-14:45:18 [INFO ] Iteration: 454, Loss: 0.038974417624547
2018-02-20-14:45:21 [INFO ] Iteration: 455, Loss: 0.038034040508002
2018-02-20-14:45:24 [INFO ] Iteration: 456, Loss: 0.039251408100419
2018-02-20-14:45:26 [INFO ] Iteration: 457, Loss: 0.039115169616495
2018-02-20-14:45:29 [INFO ] Iteration: 458, Loss: 0.038509777806107
2018-02-20-14:45:32 [INFO ] Iteration: 459, Loss: 0.040051524710092
2018-02-20-14:45:34 [INFO ] Iteration: 460, Loss: 0.039099284829511
2018-02-20-14:45:37 [INFO ] Iteration: 461, Loss: 0.040059813542545
2018-02-20-14:45:39 [INFO ] Iteration: 462, Loss: 0.040309979539142
2018-02-20-14:45:42 [INFO ] Iteration: 463, Loss: 0.039968764572919
2018-02-20-14:45:45 [INFO ] Iteration: 464, Loss: 0.039530507480512
2018-02-20-14:45:47 [INFO ] Iteration: 465, Loss: 0.039393232672506
2018-02-20-14:45:50 [INFO ] Iteration: 466, Loss: 0.038921921010091
2018-02-20-14:45:53 [INFO ] Iteration: 467, Loss: 0.038618614575036
2018-02-20-14:45:55 [INFO ] Iteration: 468, Loss: 0.040554704554173
2018-02-20-14:45:58 [INFO ] Iteration: 469, Loss: 0.038780991006858
2018-02-20-14:46:01 [INFO ] Iteration: 470, Loss: 0.04025205669972
2018-02-20-14:46:03 [INFO ] Iteration: 471, Loss: 0.039038418498695
2018-02-20-14:46:06 [INFO ] Iteration: 472, Loss: 0.040048601087319
2018-02-20-14:46:08 [INFO ] Iteration: 473, Loss: 0.039041401627341
2018-02-20-14:46:11 [INFO ] Iteration: 474, Loss: 0.038770103982719
2018-02-20-14:46:14 [INFO ] Iteration: 475, Loss: 0.039573280480189
2018-02-20-14:46:16 [INFO ] Iteration: 476, Loss: 0.040538792468382
2018-02-20-14:46:19 [INFO ] Iteration: 477, Loss: 0.039573206296331
2018-02-20-14:46:22 [INFO ] Iteration: 478, Loss: 0.041796855314554
2018-02-20-14:46:24 [INFO ] Iteration: 479, Loss: 0.039216865899489
2018-02-20-14:46:27 [INFO ] Iteration: 480, Loss: 0.038779761517525
2018-02-20-14:46:30 [INFO ] Iteration: 481, Loss: 0.038094249417167
2018-02-20-14:46:32 [INFO ] Iteration: 482, Loss: 0.038497019529439
2018-02-20-14:46:35 [INFO ] Iteration: 483, Loss: 0.037737230359777
2018-02-20-14:46:38 [INFO ] Iteration: 484, Loss: 0.039697008592826
2018-02-20-14:46:40 [INFO ] Iteration: 485, Loss: 0.039121907798011
2018-02-20-14:46:43 [INFO ] Iteration: 486, Loss: 0.037485677643839
2018-02-20-14:46:46 [INFO ] Iteration: 487, Loss: 0.03730616354202
2018-02-20-14:46:48 [INFO ] Iteration: 488, Loss: 0.039950421284316
2018-02-20-14:46:51 [INFO ] Iteration: 489, Loss: 0.03858490967524
2018-02-20-14:46:53 [INFO ] Iteration: 490, Loss: 0.04010976918135
2018-02-20-14:46:56 [INFO ] Iteration: 491, Loss: 0.039689004002348
2018-02-20-14:46:59 [INFO ] Iteration: 492, Loss: 0.039360334599397
2018-02-20-14:47:01 [INFO ] Iteration: 493, Loss: 0.040905389270487
2018-02-20-14:47:04 [INFO ] Iteration: 494, Loss: 0.039139187370615
2018-02-20-14:47:07 [INFO ] Iteration: 495, Loss: 0.038952130475973
2018-02-20-14:47:09 [INFO ] Iteration: 496, Loss: 0.038472820158845
2018-02-20-14:47:12 [INFO ] Iteration: 497, Loss: 0.038816589596108
2018-02-20-14:47:14 [INFO ] Iteration: 498, Loss: 0.041492954158615
2018-02-20-14:47:17 [INFO ] Iteration: 499, Loss: 0.040554637163507
2018-02-20-14:47:20 [INFO ] Iteration: 500, Loss: 0.039895145217967
2018-02-20-14:47:22 [INFO ] Iteration: 501, Loss: 0.040636432285646
2018-02-20-14:47:22 [INFO ] Maximum iterations reached in Gradient Descent. Loss = 0.040636432285646
