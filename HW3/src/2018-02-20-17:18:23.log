2018-02-20-17:18:32 [DEBUG] Initializing the Model
2018-02-20-17:18:32 [DEBUG] Initializing Linear Layer
2018-02-20-17:18:32 [DEBUG] Initializing BatchNormalization Layer
2018-02-20-17:18:32 [DEBUG] Initializing ReLU Layer
2018-02-20-17:18:32 [DEBUG] Initializing Linear Layer
2018-02-20-17:18:32 [DEBUG] Initializing BatchNormalization Layer
2018-02-20-17:18:32 [DEBUG] Initializing ReLU Layer
2018-02-20-17:18:32 [DEBUG] Initializing Linear Layer
2018-02-20-17:18:32 [DEBUG] Initializing Criterion Layer
2018-02-20-17:18:32 [DEBUG] Beginning Gradient Descent
2018-02-20-17:18:35 [INFO ] Iteration: 1, Loss: 0.047972213934634
2018-02-20-17:18:39 [INFO ] Iteration: 2, Loss: 0.048961959771275
2018-02-20-17:18:42 [INFO ] Iteration: 3, Loss: 0.048927468316031
2018-02-20-17:18:45 [INFO ] Iteration: 4, Loss: 0.047392168072321
2018-02-20-17:18:48 [INFO ] Iteration: 5, Loss: 0.046964122410226
2018-02-20-17:18:51 [INFO ] Iteration: 6, Loss: 0.047998065882384
2018-02-20-17:18:54 [INFO ] Iteration: 7, Loss: 0.047974557404132
2018-02-20-17:18:57 [INFO ] Iteration: 8, Loss: 0.046708096918808
2018-02-20-17:19:00 [INFO ] Iteration: 9, Loss: 0.047947601434663
2018-02-20-17:19:04 [INFO ] Iteration: 10, Loss: 0.047553115778792
2018-02-20-17:19:06 [INFO ] Iteration: 11, Loss: 0.048184574286072
2018-02-20-17:19:09 [INFO ] Iteration: 12, Loss: 0.048015669364644
2018-02-20-17:19:12 [INFO ] Iteration: 13, Loss: 0.047420517800166
2018-02-20-17:19:15 [INFO ] Iteration: 14, Loss: 0.046809347467743
2018-02-20-17:19:18 [INFO ] Iteration: 15, Loss: 0.046056502666242
2018-02-20-17:19:21 [INFO ] Iteration: 16, Loss: 0.046563781352495
2018-02-20-17:19:24 [INFO ] Iteration: 17, Loss: 0.049397017654343
2018-02-20-17:19:27 [INFO ] Iteration: 18, Loss: 0.045637740514602
2018-02-20-17:19:31 [INFO ] Iteration: 19, Loss: 0.045311558968515
2018-02-20-17:19:34 [INFO ] Iteration: 20, Loss: 0.048686759605603
2018-02-20-17:19:37 [INFO ] Iteration: 21, Loss: 0.047767383389769
2018-02-20-17:19:40 [INFO ] Iteration: 22, Loss: 0.046186603252344
2018-02-20-17:19:43 [INFO ] Iteration: 23, Loss: 0.046925625391968
2018-02-20-17:19:45 [INFO ] Iteration: 24, Loss: 0.047908947173372
2018-02-20-17:19:48 [INFO ] Iteration: 25, Loss: 0.047582784734028
2018-02-20-17:19:52 [INFO ] Iteration: 26, Loss: 0.047168029017226
2018-02-20-17:19:55 [INFO ] Iteration: 27, Loss: 0.045986221304133
2018-02-20-17:19:58 [INFO ] Iteration: 28, Loss: 0.046631607679459
2018-02-20-17:20:01 [INFO ] Iteration: 29, Loss: 0.045009559832327
2018-02-20-17:20:04 [INFO ] Iteration: 30, Loss: 0.047390440173884
2018-02-20-17:20:07 [INFO ] Iteration: 31, Loss: 0.04657206865395
2018-02-20-17:20:10 [INFO ] Iteration: 32, Loss: 0.04725214551542
2018-02-20-17:20:12 [INFO ] Iteration: 33, Loss: 0.047686853870775
2018-02-20-17:20:15 [INFO ] Iteration: 34, Loss: 0.047677367188334
2018-02-20-17:20:18 [INFO ] Iteration: 35, Loss: 0.046652945603832
2018-02-20-17:20:21 [INFO ] Iteration: 36, Loss: 0.047102805602726
2018-02-20-17:20:24 [INFO ] Iteration: 37, Loss: 0.046888131541217
2018-02-20-17:20:26 [INFO ] Iteration: 38, Loss: 0.046965549767511
2018-02-20-17:20:30 [INFO ] Iteration: 39, Loss: 0.046887370646394
2018-02-20-17:20:33 [INFO ] Iteration: 40, Loss: 0.045717510264943
2018-02-20-17:20:35 [INFO ] Iteration: 41, Loss: 0.046480796413491
2018-02-20-17:20:38 [INFO ] Iteration: 42, Loss: 0.04608228769954
2018-02-20-17:20:41 [INFO ] Iteration: 43, Loss: 0.046616878568249
2018-02-20-17:20:44 [INFO ] Iteration: 44, Loss: 0.046353676753637
2018-02-20-17:20:47 [INFO ] Iteration: 45, Loss: 0.046115283689356
2018-02-20-17:20:49 [INFO ] Iteration: 46, Loss: 0.045509787739798
2018-02-20-17:20:52 [INFO ] Iteration: 47, Loss: 0.045814752236753
2018-02-20-17:20:55 [INFO ] Iteration: 48, Loss: 0.046867533077478
2018-02-20-17:20:58 [INFO ] Iteration: 49, Loss: 0.046254018402214
2018-02-20-17:21:01 [INFO ] Iteration: 50, Loss: 0.047653417664138
2018-02-20-17:21:03 [INFO ] Iteration: 51, Loss: 0.047212819766821
2018-02-20-17:21:06 [INFO ] Iteration: 52, Loss: 0.047271003756426
2018-02-20-17:21:09 [INFO ] Iteration: 53, Loss: 0.046389368874435
2018-02-20-17:21:12 [INFO ] Iteration: 54, Loss: 0.046241711535854
2018-02-20-17:21:15 [INFO ] Iteration: 55, Loss: 0.046562310060423
2018-02-20-17:21:17 [INFO ] Iteration: 56, Loss: 0.044810876126301
2018-02-20-17:21:20 [INFO ] Iteration: 57, Loss: 0.046258977038593
2018-02-20-17:21:23 [INFO ] Iteration: 58, Loss: 0.045570796740367
2018-02-20-17:21:26 [INFO ] Iteration: 59, Loss: 0.046421126261286
2018-02-20-17:21:29 [INFO ] Iteration: 60, Loss: 0.046585432562131
2018-02-20-17:21:32 [INFO ] Iteration: 61, Loss: 0.046604594428063
2018-02-20-17:21:34 [INFO ] Iteration: 62, Loss: 0.046818492066334
2018-02-20-17:21:37 [INFO ] Iteration: 63, Loss: 0.046739400584774
2018-02-20-17:21:40 [INFO ] Iteration: 64, Loss: 0.046370980870114
2018-02-20-17:21:43 [INFO ] Iteration: 65, Loss: 0.047199714365226
2018-02-20-17:21:46 [INFO ] Iteration: 66, Loss: 0.046952560787371
2018-02-20-17:21:49 [INFO ] Iteration: 67, Loss: 0.046656113225652
2018-02-20-17:21:52 [INFO ] Iteration: 68, Loss: 0.044932910018375
2018-02-20-17:21:54 [INFO ] Iteration: 69, Loss: 0.045270642448452
2018-02-20-17:21:57 [INFO ] Iteration: 70, Loss: 0.046987585751718
2018-02-20-17:22:00 [INFO ] Iteration: 71, Loss: 0.045705227021457
2018-02-20-17:22:03 [INFO ] Iteration: 72, Loss: 0.046516615539303
2018-02-20-17:22:06 [INFO ] Iteration: 73, Loss: 0.045514118417191
2018-02-20-17:22:09 [INFO ] Iteration: 74, Loss: 0.046719487937968
2018-02-20-17:22:12 [INFO ] Iteration: 75, Loss: 0.045555658522194
2018-02-20-17:22:14 [INFO ] Iteration: 76, Loss: 0.046903748659016
2018-02-20-17:22:17 [INFO ] Iteration: 77, Loss: 0.044990977829096
2018-02-20-17:22:20 [INFO ] Iteration: 78, Loss: 0.045088628178651
2018-02-20-17:22:23 [INFO ] Iteration: 79, Loss: 0.045004082400195
2018-02-20-17:22:26 [INFO ] Iteration: 80, Loss: 0.044923892080399
2018-02-20-17:22:29 [INFO ] Iteration: 81, Loss: 0.047112902725811
2018-02-20-17:22:32 [INFO ] Iteration: 82, Loss: 0.044588426405084
2018-02-20-17:22:34 [INFO ] Iteration: 83, Loss: 0.045108949448085
2018-02-20-17:22:37 [INFO ] Iteration: 84, Loss: 0.047499195096113
2018-02-20-17:22:40 [INFO ] Iteration: 85, Loss: 0.045132005304892
2018-02-20-17:22:43 [INFO ] Iteration: 86, Loss: 0.045916378318815
2018-02-20-17:22:46 [INFO ] Iteration: 87, Loss: 0.045347013212561
2018-02-20-17:22:49 [INFO ] Iteration: 88, Loss: 0.04738982057821
2018-02-20-17:22:51 [INFO ] Iteration: 89, Loss: 0.045673736239832
2018-02-20-17:22:54 [INFO ] Iteration: 90, Loss: 0.047227709569472
2018-02-20-17:22:57 [INFO ] Iteration: 91, Loss: 0.046614152325339
2018-02-20-17:23:00 [INFO ] Iteration: 92, Loss: 0.045075321825574
2018-02-20-17:23:03 [INFO ] Iteration: 93, Loss: 0.043899564360751
2018-02-20-17:23:06 [INFO ] Iteration: 94, Loss: 0.044584417705731
2018-02-20-17:23:09 [INFO ] Iteration: 95, Loss: 0.045017616049612
2018-02-20-17:23:12 [INFO ] Iteration: 96, Loss: 0.044617906755701
2018-02-20-17:23:14 [INFO ] Iteration: 97, Loss: 0.044433340100752
2018-02-20-17:23:17 [INFO ] Iteration: 98, Loss: 0.044254961720489
2018-02-20-17:23:20 [INFO ] Iteration: 99, Loss: 0.047683198451067
2018-02-20-17:23:23 [INFO ] Iteration: 100, Loss: 0.045094393926321
2018-02-20-17:23:26 [INFO ] Iteration: 101, Loss: 0.04736059804694
2018-02-20-17:23:29 [INFO ] Iteration: 102, Loss: 0.043909715577104
2018-02-20-17:23:31 [INFO ] Iteration: 103, Loss: 0.044537941062516
2018-02-20-17:23:34 [INFO ] Iteration: 104, Loss: 0.047286489056938
2018-02-20-17:23:37 [INFO ] Iteration: 105, Loss: 0.046868975085241
2018-02-20-17:23:40 [INFO ] Iteration: 106, Loss: 0.046339824652996
2018-02-20-17:23:43 [INFO ] Iteration: 107, Loss: 0.046218822299736
2018-02-20-17:23:46 [INFO ] Iteration: 108, Loss: 0.046695002794476
2018-02-20-17:23:49 [INFO ] Iteration: 109, Loss: 0.046047813076557
2018-02-20-17:23:52 [INFO ] Iteration: 110, Loss: 0.046741463078583
2018-02-20-17:23:54 [INFO ] Iteration: 111, Loss: 0.044960199549641
2018-02-20-17:23:57 [INFO ] Iteration: 112, Loss: 0.045059181263367
2018-02-20-17:24:00 [INFO ] Iteration: 113, Loss: 0.046683740417685
2018-02-20-17:24:03 [INFO ] Iteration: 114, Loss: 0.045016593021617
2018-02-20-17:24:06 [INFO ] Iteration: 115, Loss: 0.044915764547412
2018-02-20-17:24:09 [INFO ] Iteration: 116, Loss: 0.044825587310988
2018-02-20-17:24:12 [INFO ] Iteration: 117, Loss: 0.044910936552977
2018-02-20-17:24:14 [INFO ] Iteration: 118, Loss: 0.044920035614352
2018-02-20-17:24:17 [INFO ] Iteration: 119, Loss: 0.044236125876481
2018-02-20-17:24:20 [INFO ] Iteration: 120, Loss: 0.045945380985638
2018-02-20-17:24:23 [INFO ] Iteration: 121, Loss: 0.046496247127342
2018-02-20-17:24:26 [INFO ] Iteration: 122, Loss: 0.045580754535432
2018-02-20-17:24:29 [INFO ] Iteration: 123, Loss: 0.045703689978731
2018-02-20-17:24:32 [INFO ] Iteration: 124, Loss: 0.046445912250645
2018-02-20-17:24:34 [INFO ] Iteration: 125, Loss: 0.045113753902634
2018-02-20-17:24:37 [INFO ] Iteration: 126, Loss: 0.045973243474076
2018-02-20-17:24:40 [INFO ] Iteration: 127, Loss: 0.044158337530897
2018-02-20-17:24:43 [INFO ] Iteration: 128, Loss: 0.044789685569371
2018-02-20-17:24:46 [INFO ] Iteration: 129, Loss: 0.045455723620962
2018-02-20-17:24:49 [INFO ] Iteration: 130, Loss: 0.045322239188484
2018-02-20-17:24:52 [INFO ] Iteration: 131, Loss: 0.045545982487661
2018-02-20-17:24:55 [INFO ] Iteration: 132, Loss: 0.046100727365122
2018-02-20-17:24:57 [INFO ] Iteration: 133, Loss: 0.046197039295301
2018-02-20-17:25:00 [INFO ] Iteration: 134, Loss: 0.044938187810508
2018-02-20-17:25:03 [INFO ] Iteration: 135, Loss: 0.044622796211537
2018-02-20-17:25:06 [INFO ] Iteration: 136, Loss: 0.046067670224823
2018-02-20-17:25:09 [INFO ] Iteration: 137, Loss: 0.04556620444365
2018-02-20-17:25:12 [INFO ] Iteration: 138, Loss: 0.044356252217717
2018-02-20-17:25:15 [INFO ] Iteration: 139, Loss: 0.046293324442148
2018-02-20-17:25:17 [INFO ] Iteration: 140, Loss: 0.044610267401712
2018-02-20-17:25:20 [INFO ] Iteration: 141, Loss: 0.044791038786916
2018-02-20-17:25:23 [INFO ] Iteration: 142, Loss: 0.044128182526534
2018-02-20-17:25:26 [INFO ] Iteration: 143, Loss: 0.044534702575002
2018-02-20-17:25:29 [INFO ] Iteration: 144, Loss: 0.045414792765213
2018-02-20-17:25:32 [INFO ] Iteration: 145, Loss: 0.044801988487511
2018-02-20-17:25:35 [INFO ] Iteration: 146, Loss: 0.045192794154029
2018-02-20-17:25:37 [INFO ] Iteration: 147, Loss: 0.044962357239009
2018-02-20-17:25:40 [INFO ] Iteration: 148, Loss: 0.044086383900015
2018-02-20-17:25:43 [INFO ] Iteration: 149, Loss: 0.045144346708207
2018-02-20-17:25:46 [INFO ] Iteration: 150, Loss: 0.045554220637477
2018-02-20-17:25:49 [INFO ] Iteration: 151, Loss: 0.045161849577588
2018-02-20-17:25:52 [INFO ] Iteration: 152, Loss: 0.044709016270516
2018-02-20-17:25:55 [INFO ] Iteration: 153, Loss: 0.043849689931872
2018-02-20-17:25:57 [INFO ] Iteration: 154, Loss: 0.045475129036695
2018-02-20-17:26:00 [INFO ] Iteration: 155, Loss: 0.046297735995842
2018-02-20-17:26:03 [INFO ] Iteration: 156, Loss: 0.045212423737807
2018-02-20-17:26:06 [INFO ] Iteration: 157, Loss: 0.046073733950214
2018-02-20-17:26:09 [INFO ] Iteration: 158, Loss: 0.044499294933057
2018-02-20-17:26:12 [INFO ] Iteration: 159, Loss: 0.044748199146121
2018-02-20-17:26:15 [INFO ] Iteration: 160, Loss: 0.04428925110293
2018-02-20-17:26:17 [INFO ] Iteration: 161, Loss: 0.046361945192306
2018-02-20-17:26:20 [INFO ] Iteration: 162, Loss: 0.046232213147742
2018-02-20-17:26:23 [INFO ] Iteration: 163, Loss: 0.044481820038517
2018-02-20-17:26:26 [INFO ] Iteration: 164, Loss: 0.044735584553965
2018-02-20-17:26:29 [INFO ] Iteration: 165, Loss: 0.043955468266569
2018-02-20-17:26:32 [INFO ] Iteration: 166, Loss: 0.045047271426916
2018-02-20-17:26:35 [INFO ] Iteration: 167, Loss: 0.044810816706359
2018-02-20-17:26:37 [INFO ] Iteration: 168, Loss: 0.044508047186326
2018-02-20-17:26:40 [INFO ] Iteration: 169, Loss: 0.046800685020113
2018-02-20-17:26:43 [INFO ] Iteration: 170, Loss: 0.044856103253593
2018-02-20-17:26:46 [INFO ] Iteration: 171, Loss: 0.043974397128276
2018-02-20-17:26:49 [INFO ] Iteration: 172, Loss: 0.045929170099484
2018-02-20-17:26:52 [INFO ] Iteration: 173, Loss: 0.042931017842765
2018-02-20-17:26:55 [INFO ] Iteration: 174, Loss: 0.044662277512747
2018-02-20-17:26:57 [INFO ] Iteration: 175, Loss: 0.04561758773673
2018-02-20-17:27:00 [INFO ] Iteration: 176, Loss: 0.04502820867597
2018-02-20-17:27:03 [INFO ] Iteration: 177, Loss: 0.045057474692136
2018-02-20-17:27:06 [INFO ] Iteration: 178, Loss: 0.044085106894758
2018-02-20-17:27:09 [INFO ] Iteration: 179, Loss: 0.04567932409994
2018-02-20-17:27:12 [INFO ] Iteration: 180, Loss: 0.044337578014854
2018-02-20-17:27:14 [INFO ] Iteration: 181, Loss: 0.044930118614008
2018-02-20-17:27:17 [INFO ] Iteration: 182, Loss: 0.046025982569387
2018-02-20-17:27:20 [INFO ] Iteration: 183, Loss: 0.043983711246083
2018-02-20-17:27:23 [INFO ] Iteration: 184, Loss: 0.04432103211237
2018-02-20-17:27:26 [INFO ] Iteration: 185, Loss: 0.044770754017108
2018-02-20-17:27:29 [INFO ] Iteration: 186, Loss: 0.045656917703986
2018-02-20-17:27:32 [INFO ] Iteration: 187, Loss: 0.045035573993007
2018-02-20-17:27:34 [INFO ] Iteration: 188, Loss: 0.044608934762441
2018-02-20-17:27:37 [INFO ] Iteration: 189, Loss: 0.046310481822761
2018-02-20-17:27:40 [INFO ] Iteration: 190, Loss: 0.044531444919375
2018-02-20-17:27:43 [INFO ] Iteration: 191, Loss: 0.044761635211993
2018-02-20-17:27:46 [INFO ] Iteration: 192, Loss: 0.045509905181763
2018-02-20-17:27:49 [INFO ] Iteration: 193, Loss: 0.044823003484796
2018-02-20-17:27:52 [INFO ] Iteration: 194, Loss: 0.043818108264267
2018-02-20-17:27:54 [INFO ] Iteration: 195, Loss: 0.044770810066304
2018-02-20-17:27:57 [INFO ] Iteration: 196, Loss: 0.043808702378395
2018-02-20-17:28:00 [INFO ] Iteration: 197, Loss: 0.04313372977543
2018-02-20-17:28:03 [INFO ] Iteration: 198, Loss: 0.045023769288354
2018-02-20-17:28:06 [INFO ] Iteration: 199, Loss: 0.044634555784439
2018-02-20-17:28:09 [INFO ] Iteration: 200, Loss: 0.046989560765444
2018-02-20-17:28:12 [INFO ] Iteration: 201, Loss: 0.045491348389552
2018-02-20-17:28:15 [INFO ] Iteration: 202, Loss: 0.043786826178923
2018-02-20-17:28:17 [INFO ] Iteration: 203, Loss: 0.042850995665796
2018-02-20-17:28:20 [INFO ] Iteration: 204, Loss: 0.045547981653374
2018-02-20-17:28:23 [INFO ] Iteration: 205, Loss: 0.045149592811394
2018-02-20-17:28:26 [INFO ] Iteration: 206, Loss: 0.045733705271446
2018-02-20-17:28:29 [INFO ] Iteration: 207, Loss: 0.043961960520662
2018-02-20-17:28:32 [INFO ] Iteration: 208, Loss: 0.044547383315036
2018-02-20-17:28:35 [INFO ] Iteration: 209, Loss: 0.045383562711732
2018-02-20-17:28:38 [INFO ] Iteration: 210, Loss: 0.044904182493426
2018-02-20-17:28:40 [INFO ] Iteration: 211, Loss: 0.044338214235399
2018-02-20-17:28:43 [INFO ] Iteration: 212, Loss: 0.045672687401593
2018-02-20-17:28:46 [INFO ] Iteration: 213, Loss: 0.045598679721058
2018-02-20-17:28:49 [INFO ] Iteration: 214, Loss: 0.044449697484592
2018-02-20-17:28:52 [INFO ] Iteration: 215, Loss: 0.044846645388252
2018-02-20-17:28:55 [INFO ] Iteration: 216, Loss: 0.044140238081521
2018-02-20-17:28:58 [INFO ] Iteration: 217, Loss: 0.045714454627112
2018-02-20-17:29:01 [INFO ] Iteration: 218, Loss: 0.044584309042867
2018-02-20-17:29:03 [INFO ] Iteration: 219, Loss: 0.043999059288718
2018-02-20-17:29:06 [INFO ] Iteration: 220, Loss: 0.043585793310655
2018-02-20-17:29:09 [INFO ] Iteration: 221, Loss: 0.046130952271014
2018-02-20-17:29:12 [INFO ] Iteration: 222, Loss: 0.044390132724964
2018-02-20-17:29:15 [INFO ] Iteration: 223, Loss: 0.045513079033044
2018-02-20-17:29:18 [INFO ] Iteration: 224, Loss: 0.044411452463332
2018-02-20-17:29:21 [INFO ] Iteration: 225, Loss: 0.044262918543395
2018-02-20-17:29:23 [INFO ] Iteration: 226, Loss: 0.044263244396705
2018-02-20-17:29:26 [INFO ] Iteration: 227, Loss: 0.044336829339434
2018-02-20-17:29:29 [INFO ] Iteration: 228, Loss: 0.044526878340778
2018-02-20-17:29:32 [INFO ] Iteration: 229, Loss: 0.045892071950852
2018-02-20-17:29:35 [INFO ] Iteration: 230, Loss: 0.044879264548219
2018-02-20-17:29:38 [INFO ] Iteration: 231, Loss: 0.044538959962596
2018-02-20-17:29:41 [INFO ] Iteration: 232, Loss: 0.044585670277451
2018-02-20-17:29:43 [INFO ] Iteration: 233, Loss: 0.044644667251929
2018-02-20-17:29:46 [INFO ] Iteration: 234, Loss: 0.043431580619747
2018-02-20-17:29:49 [INFO ] Iteration: 235, Loss: 0.043716691045733
2018-02-20-17:29:52 [INFO ] Iteration: 236, Loss: 0.045713354127752
2018-02-20-17:29:55 [INFO ] Iteration: 237, Loss: 0.045053228760871
2018-02-20-17:29:58 [INFO ] Iteration: 238, Loss: 0.043376535383687
2018-02-20-17:30:01 [INFO ] Iteration: 239, Loss: 0.044334733261756
2018-02-20-17:30:03 [INFO ] Iteration: 240, Loss: 0.044108522339699
2018-02-20-17:30:06 [INFO ] Iteration: 241, Loss: 0.044676400085958
2018-02-20-17:30:09 [INFO ] Iteration: 242, Loss: 0.044407751942354
2018-02-20-17:30:12 [INFO ] Iteration: 243, Loss: 0.044610252823863
2018-02-20-17:30:15 [INFO ] Iteration: 244, Loss: 0.043377720079533
2018-02-20-17:30:18 [INFO ] Iteration: 245, Loss: 0.045119106332203
2018-02-20-17:30:21 [INFO ] Iteration: 246, Loss: 0.045916846918921
2018-02-20-17:30:23 [INFO ] Iteration: 247, Loss: 0.044775086189542
2018-02-20-17:30:26 [INFO ] Iteration: 248, Loss: 0.044162733863217
2018-02-20-17:30:29 [INFO ] Iteration: 249, Loss: 0.043905893485913
2018-02-20-17:30:32 [INFO ] Iteration: 250, Loss: 0.045508250410639
2018-02-20-17:30:35 [INFO ] Iteration: 251, Loss: 0.044253293324711
2018-02-20-17:30:38 [INFO ] Iteration: 252, Loss: 0.043987396101004
2018-02-20-17:30:41 [INFO ] Iteration: 253, Loss: 0.043669423690098
2018-02-20-17:30:43 [INFO ] Iteration: 254, Loss: 0.04438823877034
2018-02-20-17:30:46 [INFO ] Iteration: 255, Loss: 0.044183293525114
2018-02-20-17:30:49 [INFO ] Iteration: 256, Loss: 0.043994288086018
2018-02-20-17:30:52 [INFO ] Iteration: 257, Loss: 0.044016456684699
2018-02-20-17:30:55 [INFO ] Iteration: 258, Loss: 0.045755074247262
2018-02-20-17:30:58 [INFO ] Iteration: 259, Loss: 0.044153519101181
2018-02-20-17:31:01 [INFO ] Iteration: 260, Loss: 0.043995700320826
2018-02-20-17:31:03 [INFO ] Iteration: 261, Loss: 0.044550795299724
2018-02-20-17:31:06 [INFO ] Iteration: 262, Loss: 0.044280943528787
2018-02-20-17:31:09 [INFO ] Iteration: 263, Loss: 0.04377904445982
2018-02-20-17:31:12 [INFO ] Iteration: 264, Loss: 0.042926928668937
2018-02-20-17:31:15 [INFO ] Iteration: 265, Loss: 0.044690300834565
2018-02-20-17:31:18 [INFO ] Iteration: 266, Loss: 0.043914859072615
2018-02-20-17:31:21 [INFO ] Iteration: 267, Loss: 0.043019071383527
2018-02-20-17:31:23 [INFO ] Iteration: 268, Loss: 0.044770414764642
2018-02-20-17:31:26 [INFO ] Iteration: 269, Loss: 0.044700112353903
2018-02-20-17:31:29 [INFO ] Iteration: 270, Loss: 0.043471658903654
2018-02-20-17:31:32 [INFO ] Iteration: 271, Loss: 0.046219205771506
2018-02-20-17:31:35 [INFO ] Iteration: 272, Loss: 0.044881491384279
2018-02-20-17:31:38 [INFO ] Iteration: 273, Loss: 0.044387568241693
2018-02-20-17:31:41 [INFO ] Iteration: 274, Loss: 0.044731537730312
2018-02-20-17:31:44 [INFO ] Iteration: 275, Loss: 0.045249922543828
2018-02-20-17:31:46 [INFO ] Iteration: 276, Loss: 0.045136180902545
2018-02-20-17:31:49 [INFO ] Iteration: 277, Loss: 0.045263180952088
2018-02-20-17:31:52 [INFO ] Iteration: 278, Loss: 0.043549115080328
2018-02-20-17:31:55 [INFO ] Iteration: 279, Loss: 0.044074691180662
2018-02-20-17:31:58 [INFO ] Iteration: 280, Loss: 0.043573328522631
2018-02-20-17:32:01 [INFO ] Iteration: 281, Loss: 0.04312800783438
2018-02-20-17:32:04 [INFO ] Iteration: 282, Loss: 0.044830489025884
2018-02-20-17:32:07 [INFO ] Iteration: 283, Loss: 0.043388880843382
2018-02-20-17:32:09 [INFO ] Iteration: 284, Loss: 0.043798670050138
2018-02-20-17:32:12 [INFO ] Iteration: 285, Loss: 0.045012900486231
2018-02-20-17:32:15 [INFO ] Iteration: 286, Loss: 0.043142092523237
2018-02-20-17:32:18 [INFO ] Iteration: 287, Loss: 0.042422325372992
2018-02-20-17:32:21 [INFO ] Iteration: 288, Loss: 0.045700176975967
2018-02-20-17:32:24 [INFO ] Iteration: 289, Loss: 0.044948917043388
2018-02-20-17:32:27 [INFO ] Iteration: 290, Loss: 0.044345905889458
2018-02-20-17:32:29 [INFO ] Iteration: 291, Loss: 0.04295095205724
2018-02-20-17:32:32 [INFO ] Iteration: 292, Loss: 0.04484622320932
2018-02-20-17:32:35 [INFO ] Iteration: 293, Loss: 0.045415767485644
2018-02-20-17:32:38 [INFO ] Iteration: 294, Loss: 0.043573523943456
2018-02-20-17:32:41 [INFO ] Iteration: 295, Loss: 0.042717377204497
2018-02-20-17:32:44 [INFO ] Iteration: 296, Loss: 0.044452429721216
2018-02-20-17:32:47 [INFO ] Iteration: 297, Loss: 0.04396367558237
2018-02-20-17:32:49 [INFO ] Iteration: 298, Loss: 0.043362924085527
2018-02-20-17:32:52 [INFO ] Iteration: 299, Loss: 0.043555264650843
2018-02-20-17:32:55 [INFO ] Iteration: 300, Loss: 0.044333980307939
2018-02-20-17:32:58 [INFO ] Iteration: 301, Loss: 0.043662782595511
2018-02-20-17:33:01 [INFO ] Iteration: 302, Loss: 0.044602239298631
2018-02-20-17:33:04 [INFO ] Iteration: 303, Loss: 0.044561514595147
2018-02-20-17:33:07 [INFO ] Iteration: 304, Loss: 0.044373066435607
2018-02-20-17:33:10 [INFO ] Iteration: 305, Loss: 0.043378130450693
2018-02-20-17:33:12 [INFO ] Iteration: 306, Loss: 0.044794007210022
2018-02-20-17:33:15 [INFO ] Iteration: 307, Loss: 0.044069499311988
2018-02-20-17:33:18 [INFO ] Iteration: 308, Loss: 0.044285496557612
2018-02-20-17:33:21 [INFO ] Iteration: 309, Loss: 0.044438525886762
2018-02-20-17:33:24 [INFO ] Iteration: 310, Loss: 0.044470140466489
2018-02-20-17:33:27 [INFO ] Iteration: 311, Loss: 0.043970052478064
2018-02-20-17:33:30 [INFO ] Iteration: 312, Loss: 0.043582273886635
2018-02-20-17:33:33 [INFO ] Iteration: 313, Loss: 0.044660617796888
2018-02-20-17:33:35 [INFO ] Iteration: 314, Loss: 0.044800184846303
2018-02-20-17:33:38 [INFO ] Iteration: 315, Loss: 0.043977040556532
2018-02-20-17:33:41 [INFO ] Iteration: 316, Loss: 0.043724907525778
2018-02-20-17:33:44 [INFO ] Iteration: 317, Loss: 0.044030184567914
2018-02-20-17:33:47 [INFO ] Iteration: 318, Loss: 0.045152075370368
2018-02-20-17:33:50 [INFO ] Iteration: 319, Loss: 0.044934531164648
2018-02-20-17:33:53 [INFO ] Iteration: 320, Loss: 0.044194551938205
2018-02-20-17:33:55 [INFO ] Iteration: 321, Loss: 0.043889932195739
2018-02-20-17:33:58 [INFO ] Iteration: 322, Loss: 0.043374189821479
2018-02-20-17:34:01 [INFO ] Iteration: 323, Loss: 0.044474772331486
2018-02-20-17:34:04 [INFO ] Iteration: 324, Loss: 0.044249202764579
2018-02-20-17:34:07 [INFO ] Iteration: 325, Loss: 0.044415039080203
2018-02-20-17:34:10 [INFO ] Iteration: 326, Loss: 0.043832840407561
2018-02-20-17:34:13 [INFO ] Iteration: 327, Loss: 0.044575322933136
2018-02-20-17:34:15 [INFO ] Iteration: 328, Loss: 0.042979119099268
2018-02-20-17:34:18 [INFO ] Iteration: 329, Loss: 0.044118593379456
2018-02-20-17:34:21 [INFO ] Iteration: 330, Loss: 0.044400845772946
2018-02-20-17:34:24 [INFO ] Iteration: 331, Loss: 0.043484874944181
2018-02-20-17:34:27 [INFO ] Iteration: 332, Loss: 0.042236426480314
2018-02-20-17:34:30 [INFO ] Iteration: 333, Loss: 0.043642677860979
2018-02-20-17:34:33 [INFO ] Iteration: 334, Loss: 0.042192722176184
2018-02-20-17:34:36 [INFO ] Iteration: 335, Loss: 0.043681567671761
2018-02-20-17:34:38 [INFO ] Iteration: 336, Loss: 0.04522730364451
2018-02-20-17:34:41 [INFO ] Iteration: 337, Loss: 0.044055367707844
2018-02-20-17:34:44 [INFO ] Iteration: 338, Loss: 0.042400992970735
2018-02-20-17:34:47 [INFO ] Iteration: 339, Loss: 0.04433563938129
2018-02-20-17:34:50 [INFO ] Iteration: 340, Loss: 0.044047702901435
2018-02-20-17:34:53 [INFO ] Iteration: 341, Loss: 0.043821064111457
2018-02-20-17:34:56 [INFO ] Iteration: 342, Loss: 0.043268007306619
2018-02-20-17:34:58 [INFO ] Iteration: 343, Loss: 0.043615475525264
2018-02-20-17:35:01 [INFO ] Iteration: 344, Loss: 0.043470026369137
2018-02-20-17:35:04 [INFO ] Iteration: 345, Loss: 0.044370031430063
2018-02-20-17:35:07 [INFO ] Iteration: 346, Loss: 0.04353441326829
2018-02-20-17:35:10 [INFO ] Iteration: 347, Loss: 0.044042124227497
2018-02-20-17:35:13 [INFO ] Iteration: 348, Loss: 0.042615401945061
2018-02-20-17:35:16 [INFO ] Iteration: 349, Loss: 0.043216525796183
2018-02-20-17:35:19 [INFO ] Iteration: 350, Loss: 0.042869219225803
2018-02-20-17:35:21 [INFO ] Iteration: 351, Loss: 0.042621385319247
2018-02-20-17:35:24 [INFO ] Iteration: 352, Loss: 0.041918135266633
2018-02-20-17:35:27 [INFO ] Iteration: 353, Loss: 0.042447016983414
2018-02-20-17:35:30 [INFO ] Iteration: 354, Loss: 0.045575013658825
2018-02-20-17:35:33 [INFO ] Iteration: 355, Loss: 0.04430688736917
2018-02-20-17:35:36 [INFO ] Iteration: 356, Loss: 0.043140771540045
2018-02-20-17:35:39 [INFO ] Iteration: 357, Loss: 0.043266483995633
2018-02-20-17:35:41 [INFO ] Iteration: 358, Loss: 0.045274362714547
2018-02-20-17:35:44 [INFO ] Iteration: 359, Loss: 0.044245808799152
2018-02-20-17:35:47 [INFO ] Iteration: 360, Loss: 0.044499502966937
2018-02-20-17:35:50 [INFO ] Iteration: 361, Loss: 0.044002804233284
2018-02-20-17:35:53 [INFO ] Iteration: 362, Loss: 0.04299053631672
2018-02-20-17:35:56 [INFO ] Iteration: 363, Loss: 0.042380073761692
2018-02-20-17:35:59 [INFO ] Iteration: 364, Loss: 0.04411407877423
2018-02-20-17:36:01 [INFO ] Iteration: 365, Loss: 0.044271307453349
2018-02-20-17:36:04 [INFO ] Iteration: 366, Loss: 0.043406374615398
2018-02-20-17:36:07 [INFO ] Iteration: 367, Loss: 0.044205760192816
2018-02-20-17:36:10 [INFO ] Iteration: 368, Loss: 0.043705341048577
2018-02-20-17:36:13 [INFO ] Iteration: 369, Loss: 0.044307169904402
2018-02-20-17:36:16 [INFO ] Iteration: 370, Loss: 0.043748051399896
2018-02-20-17:36:19 [INFO ] Iteration: 371, Loss: 0.045287876734135
2018-02-20-17:36:22 [INFO ] Iteration: 372, Loss: 0.044683696974913
2018-02-20-17:36:24 [INFO ] Iteration: 373, Loss: 0.043330947505515
2018-02-20-17:36:27 [INFO ] Iteration: 374, Loss: 0.043885568444487
2018-02-20-17:36:30 [INFO ] Iteration: 375, Loss: 0.044004811862605
2018-02-20-17:36:33 [INFO ] Iteration: 376, Loss: 0.043533836446896
2018-02-20-17:36:36 [INFO ] Iteration: 377, Loss: 0.042936380560576
2018-02-20-17:36:39 [INFO ] Iteration: 378, Loss: 0.042981555485667
2018-02-20-17:36:42 [INFO ] Iteration: 379, Loss: 0.044521706226733
2018-02-20-17:36:44 [INFO ] Iteration: 380, Loss: 0.043646633867041
2018-02-20-17:36:47 [INFO ] Iteration: 381, Loss: 0.043233510385235
2018-02-20-17:36:50 [INFO ] Iteration: 382, Loss: 0.044140457637263
2018-02-20-17:36:53 [INFO ] Iteration: 383, Loss: 0.044153755367993
2018-02-20-17:36:56 [INFO ] Iteration: 384, Loss: 0.043427931770854
2018-02-20-17:36:59 [INFO ] Iteration: 385, Loss: 0.042868998164394
2018-02-20-17:37:02 [INFO ] Iteration: 386, Loss: 0.042855626215282
2018-02-20-17:37:05 [INFO ] Iteration: 387, Loss: 0.042152015377755
2018-02-20-17:37:07 [INFO ] Iteration: 388, Loss: 0.044449311199958
2018-02-20-17:37:10 [INFO ] Iteration: 389, Loss: 0.044135603034351
2018-02-20-17:37:13 [INFO ] Iteration: 390, Loss: 0.043439461828502
2018-02-20-17:37:16 [INFO ] Iteration: 391, Loss: 0.043458761188078
2018-02-20-17:37:19 [INFO ] Iteration: 392, Loss: 0.043773396016331
2018-02-20-17:37:22 [INFO ] Iteration: 393, Loss: 0.043490628367735
2018-02-20-17:37:25 [INFO ] Iteration: 394, Loss: 0.043840384522688
2018-02-20-17:37:27 [INFO ] Iteration: 395, Loss: 0.043484763268456
2018-02-20-17:37:30 [INFO ] Iteration: 396, Loss: 0.042725168944592
2018-02-20-17:37:33 [INFO ] Iteration: 397, Loss: 0.04498956637772
2018-02-20-17:37:36 [INFO ] Iteration: 398, Loss: 0.043475601581699
2018-02-20-17:37:39 [INFO ] Iteration: 399, Loss: 0.043761583826824
2018-02-20-17:37:42 [INFO ] Iteration: 400, Loss: 0.043726939977965
2018-02-20-17:37:45 [INFO ] Iteration: 401, Loss: 0.043677659097649
2018-02-20-17:37:47 [INFO ] Iteration: 402, Loss: 0.043095633827041
2018-02-20-17:37:50 [INFO ] Iteration: 403, Loss: 0.04261641008032
2018-02-20-17:37:53 [INFO ] Iteration: 404, Loss: 0.043359690871071
2018-02-20-17:37:56 [INFO ] Iteration: 405, Loss: 0.044166622287699
2018-02-20-17:37:59 [INFO ] Iteration: 406, Loss: 0.044443091088358
2018-02-20-17:38:02 [INFO ] Iteration: 407, Loss: 0.043637735890028
2018-02-20-17:38:05 [INFO ] Iteration: 408, Loss: 0.043459552404068
2018-02-20-17:38:07 [INFO ] Iteration: 409, Loss: 0.043049291982788
2018-02-20-17:38:10 [INFO ] Iteration: 410, Loss: 0.043554308269735
2018-02-20-17:38:13 [INFO ] Iteration: 411, Loss: 0.043225891697055
2018-02-20-17:38:16 [INFO ] Iteration: 412, Loss: 0.044024378043108
2018-02-20-17:38:19 [INFO ] Iteration: 413, Loss: 0.044576470107523
2018-02-20-17:38:22 [INFO ] Iteration: 414, Loss: 0.043622165041209
2018-02-20-17:38:25 [INFO ] Iteration: 415, Loss: 0.043193666036841
2018-02-20-17:38:28 [INFO ] Iteration: 416, Loss: 0.044134707348224
2018-02-20-17:38:30 [INFO ] Iteration: 417, Loss: 0.043346227030335
2018-02-20-17:38:33 [INFO ] Iteration: 418, Loss: 0.043565766318186
2018-02-20-17:38:36 [INFO ] Iteration: 419, Loss: 0.043219842295684
2018-02-20-17:38:39 [INFO ] Iteration: 420, Loss: 0.043681594069921
2018-02-20-17:38:42 [INFO ] Iteration: 421, Loss: 0.043282424071695
2018-02-20-17:38:45 [INFO ] Iteration: 422, Loss: 0.044479690221935
2018-02-20-17:38:48 [INFO ] Iteration: 423, Loss: 0.043205525793389
2018-02-20-17:38:50 [INFO ] Iteration: 424, Loss: 0.042304368671079
2018-02-20-17:38:53 [INFO ] Iteration: 425, Loss: 0.044516604234918
2018-02-20-17:38:56 [INFO ] Iteration: 426, Loss: 0.043328714888317
2018-02-20-17:38:59 [INFO ] Iteration: 427, Loss: 0.0444703924118
2018-02-20-17:39:02 [INFO ] Iteration: 428, Loss: 0.043561953536665
2018-02-20-17:39:05 [INFO ] Iteration: 429, Loss: 0.04309328280932
2018-02-20-17:39:08 [INFO ] Iteration: 430, Loss: 0.043084259652288
2018-02-20-17:39:11 [INFO ] Iteration: 431, Loss: 0.043348810654159
2018-02-20-17:39:13 [INFO ] Iteration: 432, Loss: 0.043886724459542
2018-02-20-17:39:16 [INFO ] Iteration: 433, Loss: 0.043446110519625
2018-02-20-17:39:19 [INFO ] Iteration: 434, Loss: 0.044577524909749
2018-02-20-17:39:22 [INFO ] Iteration: 435, Loss: 0.044156178184025
2018-02-20-17:39:25 [INFO ] Iteration: 436, Loss: 0.043530504931759
2018-02-20-17:39:28 [INFO ] Iteration: 437, Loss: 0.042645042420294
2018-02-20-17:39:31 [INFO ] Iteration: 438, Loss: 0.043330576669031
2018-02-20-17:39:33 [INFO ] Iteration: 439, Loss: 0.044319501153459
2018-02-20-17:39:36 [INFO ] Iteration: 440, Loss: 0.042832995581594
2018-02-20-17:39:39 [INFO ] Iteration: 441, Loss: 0.042912882443423
2018-02-20-17:39:42 [INFO ] Iteration: 442, Loss: 0.043912839815941
2018-02-20-17:39:45 [INFO ] Iteration: 443, Loss: 0.043934445914527
2018-02-20-17:39:48 [INFO ] Iteration: 444, Loss: 0.044247606694001
2018-02-20-17:39:51 [INFO ] Iteration: 445, Loss: 0.042416367614325
2018-02-20-17:39:54 [INFO ] Iteration: 446, Loss: 0.04367322968283
2018-02-20-17:39:56 [INFO ] Iteration: 447, Loss: 0.043838893035094
2018-02-20-17:39:59 [INFO ] Iteration: 448, Loss: 0.043109411848231
2018-02-20-17:40:02 [INFO ] Iteration: 449, Loss: 0.042171764431492
2018-02-20-17:40:05 [INFO ] Iteration: 450, Loss: 0.044304715373725
2018-02-20-17:40:08 [INFO ] Iteration: 451, Loss: 0.043398803981327
2018-02-20-17:40:11 [INFO ] Iteration: 452, Loss: 0.043481743067338
2018-02-20-17:40:14 [INFO ] Iteration: 453, Loss: 0.043366499677252
2018-02-20-17:40:16 [INFO ] Iteration: 454, Loss: 0.043012515744826
2018-02-20-17:40:19 [INFO ] Iteration: 455, Loss: 0.043990172817502
2018-02-20-17:40:22 [INFO ] Iteration: 456, Loss: 0.042750689101601
2018-02-20-17:40:25 [INFO ] Iteration: 457, Loss: 0.044457137599932
2018-02-20-17:40:28 [INFO ] Iteration: 458, Loss: 0.043236440585456
2018-02-20-17:40:31 [INFO ] Iteration: 459, Loss: 0.043625216502072
2018-02-20-17:40:34 [INFO ] Iteration: 460, Loss: 0.04234989401446
2018-02-20-17:40:37 [INFO ] Iteration: 461, Loss: 0.044068066568319
2018-02-20-17:40:39 [INFO ] Iteration: 462, Loss: 0.043772160121257
2018-02-20-17:40:42 [INFO ] Iteration: 463, Loss: 0.044800764902886
2018-02-20-17:40:45 [INFO ] Iteration: 464, Loss: 0.04337015586931
2018-02-20-17:40:48 [INFO ] Iteration: 465, Loss: 0.043945021837835
2018-02-20-17:40:51 [INFO ] Iteration: 466, Loss: 0.042847247044022
2018-02-20-17:40:54 [INFO ] Iteration: 467, Loss: 0.042794579585746
2018-02-20-17:40:57 [INFO ] Iteration: 468, Loss: 0.043243751198532
2018-02-20-17:40:59 [INFO ] Iteration: 469, Loss: 0.043852005422957
2018-02-20-17:41:02 [INFO ] Iteration: 470, Loss: 0.043469285194982
2018-02-20-17:41:05 [INFO ] Iteration: 471, Loss: 0.043510401740586
2018-02-20-17:41:08 [INFO ] Iteration: 472, Loss: 0.043613034425088
2018-02-20-17:41:11 [INFO ] Iteration: 473, Loss: 0.042836930923758
2018-02-20-17:41:14 [INFO ] Iteration: 474, Loss: 0.043424308458331
2018-02-20-17:41:17 [INFO ] Iteration: 475, Loss: 0.041894852782527
2018-02-20-17:41:19 [INFO ] Iteration: 476, Loss: 0.042337219183307
2018-02-20-17:41:22 [INFO ] Iteration: 477, Loss: 0.042403777752047
2018-02-20-17:41:25 [INFO ] Iteration: 478, Loss: 0.042763906238903
2018-02-20-17:41:28 [INFO ] Iteration: 479, Loss: 0.044923154427511
2018-02-20-17:41:31 [INFO ] Iteration: 480, Loss: 0.044291384064757
2018-02-20-17:41:34 [INFO ] Iteration: 481, Loss: 0.042288167098461
2018-02-20-17:41:37 [INFO ] Iteration: 482, Loss: 0.043191739006086
2018-02-20-17:41:40 [INFO ] Iteration: 483, Loss: 0.044647311844626
2018-02-20-17:41:42 [INFO ] Iteration: 484, Loss: 0.042409394695745
2018-02-20-17:41:45 [INFO ] Iteration: 485, Loss: 0.042522704953137
2018-02-20-17:41:48 [INFO ] Iteration: 486, Loss: 0.044396536748249
2018-02-20-17:41:51 [INFO ] Iteration: 487, Loss: 0.043273104297004
2018-02-20-17:41:54 [INFO ] Iteration: 488, Loss: 0.043737327303808
2018-02-20-17:41:57 [INFO ] Iteration: 489, Loss: 0.042236089218152
2018-02-20-17:42:00 [INFO ] Iteration: 490, Loss: 0.044916380912529
2018-02-20-17:42:02 [INFO ] Iteration: 491, Loss: 0.043838330137798
2018-02-20-17:42:05 [INFO ] Iteration: 492, Loss: 0.04257235814391
2018-02-20-17:42:08 [INFO ] Iteration: 493, Loss: 0.04343157562459
2018-02-20-17:42:11 [INFO ] Iteration: 494, Loss: 0.04347674554254
2018-02-20-17:42:14 [INFO ] Iteration: 495, Loss: 0.043697630799086
2018-02-20-17:42:17 [INFO ] Iteration: 496, Loss: 0.043366572739366
2018-02-20-17:42:20 [INFO ] Iteration: 497, Loss: 0.043686652209702
2018-02-20-17:42:23 [INFO ] Iteration: 498, Loss: 0.043774047274365
2018-02-20-17:42:25 [INFO ] Iteration: 499, Loss: 0.0432474509986
2018-02-20-17:42:28 [INFO ] Iteration: 500, Loss: 0.043230875820361
2018-02-20-17:42:28 [INFO ] Maximum iterations reached in Gradient Descent. Loss = 0.043230875820361
2018-02-20-17:42:28 [INFO ] Saving the model as MLP_2018-02-20-17:42:28.bin
