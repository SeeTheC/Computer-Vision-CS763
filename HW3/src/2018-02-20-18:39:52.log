2018-02-20-18:40:00 [DEBUG] Initializing the Model
2018-02-20-18:40:00 [DEBUG] Initializing Linear Layer
2018-02-20-18:40:00 [DEBUG] Initializing BatchNormalization Layer
2018-02-20-18:40:00 [DEBUG] Initializing ReLU Layer
2018-02-20-18:40:00 [DEBUG] Initializing Linear Layer
2018-02-20-18:40:00 [DEBUG] Initializing BatchNormalization Layer
2018-02-20-18:40:00 [DEBUG] Initializing ReLU Layer
2018-02-20-18:40:00 [DEBUG] Initializing Linear Layer
2018-02-20-18:40:00 [DEBUG] Initializing Criterion Layer
2018-02-20-18:40:00 [INFO ] Model
[
	(1) -->	Linear: (11664 -> 50) with bias
	(2) -->	BatchNormalization
	(3) -->	ReLU
	(4) -->	Linear: (50 -> 10) with bias
	(5) -->	BatchNormalization
	(6) -->	ReLU
	(7) -->	Linear: (10 -> 6) with bias
]
2018-02-20-18:40:00 [INFO ] Learning Rate = 0.1
2018-02-20-18:40:00 [INFO ] Iterations = 500
2018-02-20-18:40:00 [INFO ] Batch Size = 300
2018-02-20-18:40:00 [DEBUG] Beginning Gradient Descent
2018-02-20-18:40:03 [INFO ] Iteration: 1, Loss: 1.8539549552026
2018-02-20-18:40:06 [INFO ] Iteration: 2, Loss: 1.9002950285513
2018-02-20-18:40:09 [INFO ] Iteration: 3, Loss: 1.8386322626832
2018-02-20-18:40:12 [INFO ] Iteration: 4, Loss: 1.8992969715361
2018-02-20-18:40:15 [INFO ] Iteration: 5, Loss: 1.8541222597428
2018-02-20-18:40:19 [INFO ] Iteration: 6, Loss: 1.9148012680447
2018-02-20-18:40:22 [INFO ] Iteration: 7, Loss: 1.8462284570656
2018-02-20-18:40:25 [INFO ] Iteration: 8, Loss: 1.8683696261168
2018-02-20-18:40:28 [INFO ] Iteration: 9, Loss: 1.8879507591615
2018-02-20-18:40:31 [INFO ] Iteration: 10, Loss: 1.8667305916011
2018-02-20-18:40:34 [INFO ] Iteration: 11, Loss: 1.8401443666591
2018-02-20-18:40:37 [INFO ] Iteration: 12, Loss: 1.8198300006322
2018-02-20-18:40:41 [INFO ] Iteration: 13, Loss: 1.8324192375882
2018-02-20-18:40:44 [INFO ] Iteration: 14, Loss: 1.8294477997447
2018-02-20-18:40:47 [INFO ] Iteration: 15, Loss: 1.8337524589469
2018-02-20-18:40:50 [INFO ] Iteration: 16, Loss: 1.8532523409028
2018-02-20-18:40:53 [INFO ] Iteration: 17, Loss: 1.8596468167787
2018-02-20-18:40:56 [INFO ] Iteration: 18, Loss: 1.8464874805268
2018-02-20-18:40:59 [INFO ] Iteration: 19, Loss: 1.8347108090512
